"""OpenAI analysis services."""
import streamlit as st
from config.secrets import read_secrets


@st.cache_resource(show_spinner=False)
def get_openai_client():
    """Devuelve cliente OpenAI."""
    from openai import OpenAI
    api_key = read_secrets("OPENAI_API_KEY", "")
    if not api_key:
        raise RuntimeError("Falta OPENAI_API_KEY.")
    return OpenAI(api_key=api_key)


def analyze_reactions(df_all, key):
    """Analyze reactions and patterns across Form 0‚Äì2 (para p√°gina An√°lisis de reacciones)."""
    sample = df_all.head(200).to_dict(orient="records")
    sample_txt = "\n".join([f"{i+1}) {row}" for i, row in enumerate(sample)])

    prompt = f"""
    Eres un analista de talleres educativos sobre desinformaci√≥n.

    Tienes datos combinados de tres formularios:
    - [Form 0] Contexto del grupo y del docente.
    - [Form 1] Percepciones de inseguridad y emociones previas.
    - [Form 2] Reacciones ante las noticias con diferentes encuadres narrativos.

    Cada fila puede estar vinculada por un n√∫mero de tarjeta que representa a una persona.

    Tu tarea:
    1Ô∏è‚É£ Identifica patrones de reacci√≥n emocional ante las tres noticias (miedo, enojo, empat√≠a, desconfianza, indiferencia, etc.).
    2Ô∏è‚É£ Distingue qu√© encuadres (desconfianza, polarizaci√≥n, miedo/control, historia personal) provocaron m√°s reacciones emocionales fuertes o reflexivas.
    3Ô∏è‚É£ Detecta diferencias por contexto del grupo (seg√∫n Form 0) y por percepciones iniciales (Form 1).
    4Ô∏è‚É£ Resume los hallazgos en 4 secciones:
    - "Principales patrones emocionales"
    - "Comparaci√≥n entre encuadres"
    - "Factores del contexto que influyen"
    - "Recomendaciones pedag√≥gicas para la siguiente sesi√≥n"
    5Ô∏è‚É£ Agrega un breve p√°rrafo de s√≠ntesis general para el reporte final.

    Datos:
    {sample_txt}

    Responde en Markdown estructurado.
    """
    client = get_openai_client()
    with st.spinner("üîé Analizando reacciones y patrones..."):
        resp = client.chat.completions.create(
            model="gpt-4o",
            temperature=0.4,
            max_tokens=1200,
            messages=[
                {"role":"system","content":"Eres un analista pedag√≥gico experto en alfabetizaci√≥n medi√°tica."},
                {"role":"user","content":prompt}
            ]
        )
    return resp.choices[0].message.content.strip()


def analyze_trends(form1_sample, form0_context):
    """Analyze trends and dominant themes from Form 0 and Form 1."""
    import json
    import re
    
    context_text = form0_context or "(vac√≠o)"
    sample = form1_sample or "(vac√≠o)"

    analysis_prompt = f"""
    Act√∫a como un **analista de datos cualitativos experto en comunicaci√≥n social, seguridad y percepci√≥n p√∫blica**. 
    Tu tarea es interpretar informaci√≥n proveniente de talleres educativos sobre integridad de la informaci√≥n, desinformaci√≥n y emociones sociales.

    Dispones de dos fuentes de entrada:

    [Formulario 0 ‚Äì Contexto del grupo y del entorno local]
    {context_text}

    [Formulario 1 ‚Äì Percepciones de inseguridad y consumo informativo]
    {sample}

    ---

    üéØ **Objetivo del an√°lisis:**
    Identificar el **tema o fen√≥meno dominante** que genera inseguridad entre las personas participantes, 
    entendiendo el **contexto y el tipo espec√≠fico de problema** (no solo la categor√≠a general).

    El tema dominante debe reflejar no solo "qu√©" tipo de fen√≥meno ocurre, 
    sino tambi√©n "**en qu√© contexto o modalidad**" (por ejemplo: "violencia de g√©nero en espacios p√∫blicos", 
    "criminalidad asociada al narcotr√°fico", "corrupci√≥n institucional ligada a la seguridad", etc.).

    ---

    üß© **Tareas espec√≠ficas:**
    1Ô∏è‚É£ Analiza ambas fuentes para determinar el **tema o fen√≥meno dominante** con su contexto: tipo de hecho, actores, causas y entorno social o medi√°tico.  
    2Ô∏è‚É£ Distingue las **subdimensiones o manifestaciones** del fen√≥meno (por ejemplo, "violencia" ‚Üí "violencia de g√©nero" o "violencia digital").  
    3Ô∏è‚É£ Describe las **emociones predominantes** (miedo, enojo, desconfianza, indignaci√≥n, tristeza, etc.) y su relaci√≥n con el contexto del grupo.  
    4Ô∏è‚É£ Resume las **causas percibidas** y los **actores involucrados** (autoridades, grupos delictivos, comunidad, medios, etc.).  
    5Ô∏è‚É£ Sugiere hasta **10 palabras clave** representativas del tema y su entorno.  
    6Ô∏è‚É£ Incluye **2 respuestas representativas** de los formularios que ilustren el fen√≥meno y su tono emocional.

    ---

    üìÑ **Formato de salida (JSON v√°lido y estructurado):**
    {{
    "dominant_theme": "<tema o fen√≥meno dominante, frase corta y contextualizada>",
    "rationale": "<explicaci√≥n breve en 2‚Äì4 oraciones que justifique por qu√© se identific√≥ este tema y c√≥mo se manifiesta en contexto>",
    "emotional_tone": "<emociones predominantes detectadas>",
    "top_keywords": ["<palabra1>", "<palabra2>", "<palabra3>", ...],
    "representative_answers": ["<cita1>", "<cita2>"]
    }}

    ---

    üß† **Reglas:**
    - El tema debe ser **espec√≠fico y contextual** (no solo "violencia" o "inseguridad"). Ejemplo: "violencia de g√©nero en espacios p√∫blicos", "corrupci√≥n policial asociada al narcotr√°fico", "desempleo juvenil y percepci√≥n de abandono institucional".  
    - Usa solo informaci√≥n que pueda inferirse de los datos.  
    - Mant√©n tono anal√≠tico, educativo y en espa√±ol mexicano natural.  
    - Devuelve **√∫nicamente JSON estructurado**.
    """
    
    client = get_openai_client()
    with st.spinner("üîç Analizando respuestas del Form 0 y Form 1‚Ä¶"):
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.3,
            max_tokens=900,
            messages=[
                {"role": "system", "content": "Eres un analista de datos cualitativos especializado en emociones sociales."},
                {"role": "user", "content": analysis_prompt},
            ],
        )
    text = resp.choices[0].message.content.strip()
    data = json.loads(re.search(r"\{[\s\S]*\}", text).group(0))
    return data

def analyze_final_report(
    df_long_normalized,        # DataFrame largo: Taller, Marca temporal, Encuadre, N√∫mero de tarjeta, G√©nero, Pregunta, Valor
    dominant_theme: str,       # st.session_state["dominant_theme"]
    news_blocks: list[dict],   # [{'encuadre': '...', 'text': '...'}, ...] (3 items)
    form0_context_text: str = ""  # (opcional) contexto de Form 0 en crudo o resumido
) -> str:
    """
    Genera el informe final (texto + instrucciones de gr√°ficos) usando IA,
    con contexto del tema dominante, textos y encuadres de las noticias y
    respuestas del Form 2 normalizadas (cruzadas con Form 1/0).
    Devuelve Markdown estructurado.
    """
    import pandas as pd
    import textwrap

    # 1) Compactar tablas a un muestreo legible para el prompt
    #    (evita toquetazos enormes; priorizamos filas recientes o primeras N)
    if isinstance(df_long_normalized, pd.DataFrame) and not df_long_normalized.empty:
        # Reducir a ~250 filas m√°ximo para mantener prompt controlado
        df_sample = df_long_normalized.head(250).copy()
        # Exportar a CSV inline (m√°s legible que JSON para ojos humanos del modelo)
        csv_preview = df_sample.to_csv(index=False)
    else:
        csv_preview = "(sin datos normalizados)"

    # 2) Estructurar bloque de noticias (encuadre + texto)
    news_summaries = []
    for i, nb in enumerate(news_blocks, start=1):
        enc = (nb.get("encuadre") or f"Noticia {i}").strip()
        txt = (nb.get("text") or "").strip()
        # Truncar cada noticia a ~900 caracteres por seguridad
        if len(txt) > 900:
            txt = txt[:900] + "‚Ä¶"
        news_summaries.append(f"- {enc}:\n{txt}")

    news_block_txt = "\n\n".join(news_summaries) if news_summaries else "(no hay noticias generadas)"

    # 3) Construir prompt 
    prompt = f"""
Contexto:
Se ha realizado un ejercicio donde se generaron tres noticias diferentes sobre un mismo evento,
cada una con un encuadre narrativo distinto. Los participantes completaron un formulario indicando,
para cada noticia: (a) emociones que sienten al leerla, (b) grado de confiabilidad percibida y
(c) elementos clave que llamaron su atenci√≥n.

Rol:
Eres un analista senior en ciencia de datos y visualizaci√≥n. Debes construir un informe profundo y accionable
por cada taller registrado, articulando los hallazgos con el tema dominante y el contexto narrativo de las noticias generadas.

Insumos clave del taller:
- Tema dominante (derivado del an√°lisis previo): "{dominant_theme}"
- Contexto Form 0 (resumen/fragmento): "{(form0_context_text or '').strip()}"
- Noticias generadas (encuadre + texto):
{news_block_txt}

Datos normalizados de respuestas (CSV; columnas: Taller, Marca temporal, Encuadre, N√∫mero de tarjeta, G√©nero, Pregunta, Valor):
{csv_preview}

Metodolog√≠a de an√°lisis requerida:
1) Trabaja taller por taller: identifica cada valor √∫nico de "Taller" y sintetiza las particularidades del grupo.
2) Describe c√≥mo las emociones, la confianza y los elementos clave var√≠an seg√∫n encuadre dentro de cada taller.
3) Relaciona expl√≠citamente los resultados con el tema dominante y con los fragmentos narrativos de las noticias; menciona coincidencias y tensiones.
4) Analiza diferencias relevantes por g√©nero dentro de cada taller y compara entre talleres si emergen contrastes significativos.
5) Destaca patrones transversales, correlaciones o sesgos latentes que surjan al cruzar las variables (incluyendo g√©nero, encuadre y valores reportados), se√±alando posibles riesgos o oportunidades del taller.
6) Si los datos de un taller o variable son insuficientes, ind√≠calo antes de extraer conclusiones.

Objetivo del an√°lisis (entregar texto + un gr√°fico explicativo por cada punto):
1) C√≥mo var√≠an las emociones, el nivel de confianza y los componentes clave seg√∫n el tipo de encuadre narrativo.
2) Diferencias de percepci√≥n y reacci√≥n emocional a las noticias seg√∫n el g√©nero.
3) Patrones emergentes y relaciones significativas entre variables; a partir de ellos, identifica sesgos posibles que no se hayan abordado en los an√°lisis por encuadre y por g√©nero.

Formato de salida:
Devuelve **Markdown estructurado**, con secciones claras. Dentro de cada secci√≥n, menciona expl√≠citamente los aprendizajes por taller (usa subt√≠tulos o p√°rrafos separados para cada taller cuando corresponda):
## Variaci√≥n por encuadre
- Texto anal√≠tico sint√©tico (2‚Äì4 p√°rrafos).
## Diferencias por g√©nero
- Texto anal√≠tico sint√©tico (2‚Äì3 p√°rrafos).
## Patrones y sesgos emergentes
- Texto anal√≠tico (2‚Äì4 p√°rrafos), se√±alando relaciones y sesgos potenciales derivados de las respuestas.

Reglas de estilo tipogr√°fico (alineadas con la interfaz):
- Usa encabezados y subt√≠tulos siguiendo la jerarqu√≠a Markdown indicada.
- Redacta los p√°rrafos en un tono anal√≠tico, con frases completas y claras.
- Formatea listas con guiones simples (`-`). Evita listas numeradas salvo que aporten claridad.
- Resalta conceptos clave con **negritas** cuando sea necesario, sin abusar del formato.
- Mant√©n la longitud de los p√°rrafos entre 2 y 4 oraciones para facilitar la lectura.

Reglas:
- Usa √∫nicamente informaci√≥n derivada de los datos provistos (no inventes).
- Tono anal√≠tico y educativo, claro y sint√©tico.
- No incluyas c√≥digo en la respuesta; solo recomendaciones de visualizaci√≥n y narrativa.
- Si un an√°lisis no es concluyente por falta de datos, ind√≠calo expl√≠citamente.
"""

    client = get_openai_client()
    with st.spinner("üìä Generando an√°lisis final con IA‚Ä¶"):
        resp = client.chat.completions.create(
            model="gpt-4o",
            temperature=0.35,
            max_tokens=1400,
            messages=[
                {"role": "system", "content": "Eres un analista senior en ciencia de datos y visualizaci√≥n."},
                {"role": "user", "content": textwrap.dedent(prompt).strip()},
            ],
        )
    return resp.choices[0].message.content.strip()


import json
import re
import streamlit as st
from .ai_analysis import get_openai_client


def analyze_emotions_json(df_all, dominant_theme: str, form0_context_text: str):
    """Analiza variaciones emocionales por encuadre dentro de cada taller."""
    client = get_openai_client()
    sample = df_all.head(200).to_dict(orient="records")
    sample_txt = "\n".join([f"{i+1}) {row}" for i, row in enumerate(sample)])

    prompt = f"""
Eres un analista en ciencia de datos que trabaja con talleres sobre integridad de la informaci√≥n.

Contexto:
Se han generado tres noticias distintas sobre un mismo evento, cada una con un encuadre narrativo distinto.
Los participantes respondieron un formulario indicando las emociones, nivel de confianza y elementos que llamaron su atenci√≥n.

Tema dominante: "{dominant_theme}"
Contexto Form 0: "{(form0_context_text or '').strip()}"

Datos de entrada:
{sample_txt}

---

üéØ Objetivo:
Identificar c√≥mo las **emociones** var√≠an seg√∫n el encuadre narrativo dentro de cada taller.

üß© Tareas:
1Ô∏è‚É£ Agrupa respuestas por ‚ÄúTaller‚Äù y por ‚ÄúEncuadre‚Äù.
2Ô∏è‚É£ Analiza variaciones de emociones y confianza percibida.
3Ô∏è‚É£ Resume hallazgos principales (no inventes informaci√≥n ausente).
4Ô∏è‚É£ Genera **dos preguntas de debate** para el grupo.

---

üìÑ Formato JSON:
{{
  "workshops": [
    {{
      "taller": "<nombre o c√≥digo>",
      "emociones_por_encuadre": {{
        "Desconfianza y responsabilizaci√≥n de actores": ["emocion1", "emocion2"],
        "Polarizaci√≥n social y exclusi√≥n": ["emocion1", "emocion2"],
        "Miedo y control": ["emocion1", "emocion2"]
      }},
      "resumen": "<s√≠ntesis breve del patr√≥n emocional (2‚Äì3 frases)>",
      "preguntas_discusion": ["<pregunta 1>", "<pregunta 2>"]
    }}
  ]
}}
---

üß† Reglas:
- Usa √∫nicamente la informaci√≥n visible en los datos.
- Tono anal√≠tico, educativo y sint√©tico.
- No generalices ni inventes informaci√≥n fuera del dataset.
- Si hay poca informaci√≥n, indica ‚ÄúDatos insuficientes‚Äù.
"""

    with st.spinner("Analizando emociones por encuadre..."):
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.3,
            max_tokens=1200,
            messages=[{"role": "user", "content": prompt}],
        )

    text = resp.choices[0].message.content.strip()
    data = json.loads(re.search(r"\{[\s\S]*\}", text).group(0))
    return data


def analyze_gender_impacts_json(df_all, dominant_theme: str, form0_context_text: str):
    """Analiza impactos diferenciados por g√©nero y encuadre."""
    client = get_openai_client()
    sample = df_all.head(200).to_dict(orient="records")
    sample_txt = "\n".join([f"{i+1}) {row}" for i, row in enumerate(sample)])

    prompt = f"""
Eres un analista en ciencia de datos que explora impactos interseccionales en talleres de integridad de la informaci√≥n.

Tema dominante: "{dominant_theme}"
Contexto Form 0: "{(form0_context_text or '').strip()}"

Datos combinados:
{sample_txt}

---

üéØ Objetivo:
Identificar diferencias de reacci√≥n emocional, confianza y percepci√≥n seg√∫n g√©nero y tipo de encuadre.

üß© Tareas:
1Ô∏è‚É£ Analiza respuestas por g√©nero y encuadre.
2Ô∏è‚É£ Resume patrones o contrastes significativos.
3Ô∏è‚É£ Describe correlaciones entre g√©nero, confianza y emociones.
4Ô∏è‚É£ Si los datos son limitados, ind√≠calo.
5Ô∏è‚É£ Genera dos preguntas de debate (m√°x. 20 palabras cada una).

üìÑ Formato JSON:
{{
  "analisis_genero": [
    {{
      "taller": "<c√≥digo>",
      "patrones_por_genero": {{
        "Femenino": "<s√≠ntesis de emociones y confianza>",
        "Masculino": "<s√≠ntesis de emociones y confianza>",
        "Otro/No binario": "<s√≠ntesis si aplica>"
      }},
      "hallazgos_transversales": "<resumen general de diferencias detectadas>",
      "preguntas_discusion": ["<pregunta 1>", "<pregunta 2>"]
    }}
  ]
}}
---

üß† Reglas:
- Mant√©n tono anal√≠tico y educativo.
- No generalices ni uses lenguaje discriminatorio.
- Usa solo informaci√≥n presente.
"""

    with st.spinner("Analizando impactos diferenciados por g√©nero..."):
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.35,
            max_tokens=1200,
            messages=[{"role": "user", "content": prompt}],
        )

    text = resp.choices[0].message.content.strip()
    data = json.loads(re.search(r"\{[\s\S]*\}", text).group(0))
    return data


def analyze_general_json(df_all, dominant_theme: str, form0_context_text: str):
    """An√°lisis general interseccional de emociones, confianza y sesgos cognitivos."""
    client = get_openai_client()
    sample = df_all.head(200).to_dict(orient="records")
    sample_txt = "\n".join([f"{i+1}) {row}" for i, row in enumerate(sample)])

    prompt = f"""
Eres un analista de datos cualitativos en comunicaci√≥n y percepci√≥n p√∫blica.

Tema dominante: "{dominant_theme}"
Contexto Form 0: "{(form0_context_text or '').strip()}"

Datos combinados:
{sample_txt}

---

üéØ Objetivo:
Detectar patrones transversales entre emociones, confianza, encuadres y sesgos cognitivos percibidos.

üß© Tareas:
1Ô∏è‚É£ Analiza variaciones entre encuadres narrativos.
2Ô∏è‚É£ Identifica posibles sesgos cognitivos (confirmaci√≥n, atribuci√≥n, negatividad, etc.).
3Ô∏è‚É£ Resume hallazgos principales en dos p√°rrafos breves.
4Ô∏è‚É£ Si los datos son limitados, ind√≠calo expl√≠citamente.

üìÑ Formato JSON:
{{
  "resumen_general": {{
    "patrones_transversales": "<s√≠ntesis en 3‚Äì5 oraciones>",
    "sesgos_identificados": ["<sesgo1>", "<sesgo2>"],
    "hallazgos_clave": "<resumen de 4 l√≠neas>"
  }}
}}
---

üß† Reglas:
- Tono anal√≠tico, educativo y sint√©tico.
- No inventes informaci√≥n ni generalices.
- Destaca solo correlaciones que puedan inferirse del dataset.
"""

    with st.spinner("Generando an√°lisis general del taller..."):
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.35,
            max_tokens=1200,
            messages=[{"role": "user", "content": prompt}],
        )

    text = resp.choices[0].message.content.strip()
    data = json.loads(re.search(r"\{[\s\S]*\}", text).group(0))
    return data
